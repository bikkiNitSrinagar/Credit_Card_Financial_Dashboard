{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOH1Bdsj090qoy6MA3IQIkf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bikkiNitSrinagar/Credit_Card_Financial_Dashboard/blob/main/Tensorflow_Tutorials.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 1️⃣ What is TensorFlow?\n",
        "\n",
        "TensorFlow is an open-source Deep Learning framework developed by Google.\n",
        "It is used to build and train:\n",
        "\n",
        "Neural Networks\n",
        "\n",
        "*   Deep Neural Networks\n",
        "*  CNNs (Images)\n",
        "\n",
        "*  RNNs / LSTMs (Text, Time-series)\n",
        "\n",
        "*  Transformers (Advanced)\n",
        "\n",
        "*  TensorFlow works mainly with Python.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*  Deep Neural Networks\n",
        "\n",
        "*  CNNs (Images)\n",
        "\n",
        "*  RNNs / LSTMs (Text, Time-series)\n",
        "\n",
        "*  Transformers (Advanced)\n",
        "\n",
        "TensorFlow works mainly with Python."
      ],
      "metadata": {
        "id": "Md_o03b1yvg8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why TensorFlow for Deep Learning?**\n",
        "\n",
        "*   Fast computation (CPU / GPU / TPU)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Automatic differentiation\n",
        "*   Easy model building using Keras API\n",
        "*   Widely used in research & industry\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7ndgBjdDzLXa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing TensorFlow"
      ],
      "metadata": {
        "id": "mjj2rZIrzdd6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b1a5bwyjSuR",
        "outputId": "1e204020-08dc-437d-efe6-64376cdce802"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.12.19)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.46.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2026.1.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.5)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check installation:"
      ],
      "metadata": {
        "id": "b8-QtoaozhuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJEni9dKzk27",
        "outputId": "7483f10d-0ba9-48f9-e5c6-ef120a8b8a25"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "eHTXiGJI0CX-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example:"
      ],
      "metadata": {
        "id": "SRkPLVGn0EIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "a = tf.constant([1, 2, 3])\n",
        "b = tf.constant([[1, 2], [3, 4]])\n",
        "print(a)\n",
        "print(b)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WM8G-M1z7JU",
        "outputId": "d928a13a-19e8-4198-d471-09c27e8a1dd1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[1 2]\n",
            " [3 4]], shape=(2, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor Operations"
      ],
      "metadata": {
        "id": "rxAXq3s40LCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.constant([1, 2, 3])\n",
        "y = tf.constant([4, 5, 6])\n",
        "\n",
        "print(x + y)\n",
        "print(x * y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6GwsFwN0IGx",
        "outputId": "8854e7fc-4a72-4809-b239-3b41e8a59ac7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([5 7 9], shape=(3,), dtype=int32)\n",
            "tf.Tensor([ 4 10 18], shape=(3,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5️⃣ Variables (Trainable Parameters)\n",
        "\n",
        "Variables store weights & biases."
      ],
      "metadata": {
        "id": "uOJZGcmN0SfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = tf.Variable(2.0)\n",
        "b = tf.Variable(1.0)\n",
        "\n",
        "y = w * 3 + b\n",
        "print(y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVMsUbAp0NHN",
        "outputId": "793f617b-fdb0-4d5a-ace0-a563fdd9a813"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(7.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Automatic Differentiation (GradientTape)\n",
        "\n",
        "TensorFlow automatically computes gradients."
      ],
      "metadata": {
        "id": "ulVSVzjG0V3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.Variable(3.0)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    y = x ** 2\n",
        "\n",
        "dy_dx = tape.gradient(y, x)\n",
        "print(dy_dx)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0OrroyS0fLY",
        "outputId": "d9d14002-e04c-41b0-b54c-4f7911ad3fd3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(6.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7️⃣ What is Keras?\n",
        "\n",
        "Keras is a high-level API inside TensorFlow:"
      ],
      "metadata": {
        "id": "sovrza2N0kTX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a98df0c6"
      },
      "source": [
        "# Task\n",
        "The user wants me to continue generating content for the notebook based on the provided plan. I will now generate content for the \"TensorFlow Core Concepts\" and \"TensorFlow Basic Operations\" sections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "147d1d9b"
      },
      "source": [
        "## TensorFlow Core Concepts\n",
        "\n",
        "### Subtask:\n",
        "Elaborate on the fundamental concepts of TensorFlow, including what tensors are, how operations work, and the concept of a computational graph (even if implicitly used in eager execution).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a47d892"
      },
      "source": [
        "## TensorFlow Core Concepts\n",
        "\n",
        "### Tensors: The Fundamental Data Structure\n",
        "\n",
        "In TensorFlow, a **Tensor** is the primary data structure used to represent data. Tensors are multi-dimensional arrays, similar to NumPy arrays, but with key differences that make them suitable for deep learning:\n",
        "\n",
        "*   **GPU Acceleration:** Tensors can reside in accelerator memory (like GPUs or TPUs), enabling highly efficient computations. This is crucial for deep learning models that require significant parallel processing.\n",
        "*   **Immutability (by default):** Once created, a TensorFlow `tf.Tensor` is generally immutable; its value cannot be changed. This contrasts with NumPy arrays, which are mutable. If you need a mutable tensor, TensorFlow provides `tf.Variable`.\n",
        "*   **Automatic Differentiation:** TensorFlow's `tf.Tensor` objects are part of its automatic differentiation system, allowing for automatic gradient computation, which is fundamental for training neural networks.\n",
        "\n",
        "Like NumPy arrays, tensors have a `dtype` (data type) and a `shape` (dimensions).\n",
        "\n",
        "### Operations: Building Blocks of Computation\n",
        "\n",
        "**Operations** in TensorFlow are functions that consume zero or more tensors and produce zero or more tensors. These operations can be mathematical (e.g., addition, multiplication, matrix multiplication), array manipulation (e.g., reshape, concatenate), or control flow operations. Every computation in TensorFlow is ultimately represented as an operation.\n",
        "\n",
        "For example, `tf.add()`, `tf.multiply()`, `tf.matmul()`, `tf.reduce_sum()` are all operations. When you write `x + y` with TensorFlow tensors, it's implicitly calling an addition operation.\n",
        "\n",
        "### Computational Graph: The Blueprint for Execution\n",
        "\n",
        "A **Computational Graph** (or Dataflow Graph) is a series of TensorFlow operations arranged into a graph. Each node in the graph represents an operation, and each edge represents a tensor that flows between operations. This graph serves as a blueprint for how TensorFlow will execute your computations.\n",
        "\n",
        "**Benefits of a Computational Graph:**\n",
        "\n",
        "*   **Optimization:** TensorFlow can analyze the entire graph to perform various optimizations before execution, such as common subexpression elimination, dead code elimination, and memory optimization.\n",
        "*   **Distributed Execution:** Graphs can be easily distributed across multiple devices (CPUs, GPUs, TPUs) or even multiple machines.\n",
        "*   **Deployment:** The graph can be saved and deployed without the Python code, allowing for inference in production environments with different languages or runtimes.\n",
        "\n",
        "While older versions of TensorFlow (TF1.x) required explicit graph construction (Graph mode), **TensorFlow 2.x predominantly uses Eager Execution by default.** In eager execution, operations are executed immediately, returning concrete values, much like standard Python. However, even in eager mode, TensorFlow can still implicitly build and leverage computational graphs when using `tf.function` or for model training. This allows developers to write more intuitive Python code while still benefiting from the performance and deployment advantages of graphs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed4b928d"
      },
      "source": [
        "## TensorFlow Basic Operations\n",
        "\n",
        "### Subtask:\n",
        "Add more code examples demonstrating various basic TensorFlow operations beyond simple arithmetic, such as reshaping tensors, type casting, or more complex mathematical functions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f227f77"
      },
      "source": [
        "```markdown\n",
        "6️⃣ TensorFlow Basic Operations (Advanced)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ec4320e"
      },
      "source": [
        "**Reasoning**:\n",
        "The next instruction is to demonstrate creating different types of tensors (e.g., zeros, ones, random, specific values) using TensorFlow functions. I will use `tf.zeros`, `tf.ones`, `tf.random.normal`, and `tf.fill`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "351a85c2",
        "outputId": "7645fbdc-0b1e-4ca0-a5b6-5c7fdaa2cc4f"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Create a tensor of zeros\n",
        "zeros_tensor = tf.zeros(shape=(2, 3), dtype=tf.int32)\n",
        "print(\"Tensor of zeros:\\n\", zeros_tensor)\n",
        "\n",
        "# Create a tensor of ones\n",
        "ones_tensor = tf.ones(shape=(3, 2), dtype=tf.float32)\n",
        "print(\"\\nTensor of ones:\\n\", ones_tensor)\n",
        "\n",
        "# Create a tensor with random normal distribution values\n",
        "random_normal_tensor = tf.random.normal(shape=(2, 2), mean=0.0, stddev=1.0, dtype=tf.float32)\n",
        "print(\"\\nTensor with random normal values:\\n\", random_normal_tensor)\n",
        "\n",
        "# Create a tensor filled with a specific value\n",
        "filled_tensor = tf.fill(dims=(2, 2), value=7)\n",
        "print(\"\\nTensor filled with 7:\\n\", filled_tensor)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor of zeros:\n",
            " tf.Tensor(\n",
            "[[0 0 0]\n",
            " [0 0 0]], shape=(2, 3), dtype=int32)\n",
            "\n",
            "Tensor of ones:\n",
            " tf.Tensor(\n",
            "[[1. 1.]\n",
            " [1. 1.]\n",
            " [1. 1.]], shape=(3, 2), dtype=float32)\n",
            "\n",
            "Tensor with random normal values:\n",
            " tf.Tensor(\n",
            "[[-0.31574798  1.2801917 ]\n",
            " [-1.3957142   0.0572189 ]], shape=(2, 2), dtype=float32)\n",
            "\n",
            "Tensor filled with 7:\n",
            " tf.Tensor(\n",
            "[[7 7]\n",
            " [7 7]], shape=(2, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a625a04"
      },
      "source": [
        "**Reasoning**:\n",
        "The next instruction is to demonstrate tensor manipulation operations like reshaping, concatenating, expanding dimensions, and squeezing dimensions. I will create a new code cell for these examples.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "656c0c74",
        "outputId": "9ec7b945-f687-47ab-8f8f-ea3e0b65acaa"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Original tensor\n",
        "original_tensor = tf.constant([1, 2, 3, 4, 5, 6])\n",
        "print(\"Original tensor:\\n\", original_tensor)\n",
        "\n",
        "# Reshaping a tensor\n",
        "reshaped_tensor = tf.reshape(original_tensor, shape=(2, 3))\n",
        "print(\"\\nReshaped tensor (2x3):\\n\", reshaped_tensor)\n",
        "\n",
        "# Concatenating tensors\n",
        "tensor1 = tf.constant([[1, 2], [3, 4]])\n",
        "tensor2 = tf.constant([[5, 6], [7, 8]])\n",
        "concatenated_tensor_axis0 = tf.concat([tensor1, tensor2], axis=0)\n",
        "concatenated_tensor_axis1 = tf.concat([tensor1, tensor2], axis=1)\n",
        "print(\"\\nTensor 1:\\n\", tensor1)\n",
        "print(\"Tensor 2:\\n\", tensor2)\n",
        "print(\"Concatenated along axis 0:\\n\", concatenated_tensor_axis0)\n",
        "print(\"Concatenated along axis 1:\\n\", concatenated_tensor_axis1)\n",
        "\n",
        "# Expanding dimensions\n",
        "single_dim_tensor = tf.constant([10, 20, 30])\n",
        "expanded_tensor = tf.expand_dims(single_dim_tensor, axis=0) # Add a new dimension at axis 0\n",
        "print(\"\\nSingle dimension tensor:\\n\", single_dim_tensor)\n",
        "print(\"Expanded tensor (axis=0):\\n\", expanded_tensor)\n",
        "\n",
        "# Squeezing dimensions\n",
        "squeezable_tensor = tf.constant([[[1], [2], [3]]]) # Shape (1, 3, 1)\n",
        "squeezed_tensor = tf.squeeze(squeezable_tensor) # Removes dimensions of size 1\n",
        "print(\"\\nSqueezable tensor (shape (1,3,1)):\\n\", squeezable_tensor)\n",
        "print(\"Squeezed tensor (shape (3,)):\\n\", squeezed_tensor)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor:\n",
            " tf.Tensor([1 2 3 4 5 6], shape=(6,), dtype=int32)\n",
            "\n",
            "Reshaped tensor (2x3):\n",
            " tf.Tensor(\n",
            "[[1 2 3]\n",
            " [4 5 6]], shape=(2, 3), dtype=int32)\n",
            "\n",
            "Tensor 1:\n",
            " tf.Tensor(\n",
            "[[1 2]\n",
            " [3 4]], shape=(2, 2), dtype=int32)\n",
            "Tensor 2:\n",
            " tf.Tensor(\n",
            "[[5 6]\n",
            " [7 8]], shape=(2, 2), dtype=int32)\n",
            "Concatenated along axis 0:\n",
            " tf.Tensor(\n",
            "[[1 2]\n",
            " [3 4]\n",
            " [5 6]\n",
            " [7 8]], shape=(4, 2), dtype=int32)\n",
            "Concatenated along axis 1:\n",
            " tf.Tensor(\n",
            "[[1 2 5 6]\n",
            " [3 4 7 8]], shape=(2, 4), dtype=int32)\n",
            "\n",
            "Single dimension tensor:\n",
            " tf.Tensor([10 20 30], shape=(3,), dtype=int32)\n",
            "Expanded tensor (axis=0):\n",
            " tf.Tensor([[10 20 30]], shape=(1, 3), dtype=int32)\n",
            "\n",
            "Squeezable tensor (shape (1,3,1)):\n",
            " tf.Tensor(\n",
            "[[[1]\n",
            "  [2]\n",
            "  [3]]], shape=(1, 3, 1), dtype=int32)\n",
            "Squeezed tensor (shape (3,)):\n",
            " tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5212a00"
      },
      "source": [
        "# Task\n",
        "Add a code example demonstrating `tf.cast` to convert tensors between different data types (e.g., int to float), and provide explanations for the Keras API, including Sequential and Functional models, `compile()`, and `fit()`, followed by code examples for both Keras Sequential and Functional API models, then explain `tf.GradientTape` for advanced automatic differentiation with examples for nested and persistent tapes, and finally summarize the key takeaways of TensorFlow and Keras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb1e8f8e"
      },
      "source": [
        "## Type Casting Example\n",
        "\n",
        "### Subtask:\n",
        "Add a code example demonstrating `tf.cast` to convert tensors between different data types (e.g., int to float).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b12c069c"
      },
      "source": [
        "### Type Casting: Converting Data Types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b28f149"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to demonstrate `tf.cast` as per the instructions: import TensorFlow, create an integer tensor, cast it to float, and print both original and casted tensors with their dtypes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cc4944d",
        "outputId": "84df8821-2422-466d-caf2-95f629c47bb2"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Create an integer tensor\n",
        "original_int_tensor = tf.constant([1, 2, 3, 4, 5], dtype=tf.int32)\n",
        "print(\"Original Integer Tensor:\", original_int_tensor)\n",
        "print(\"Original Tensor Dtype:\", original_int_tensor.dtype)\n",
        "\n",
        "# Cast the integer tensor to a float tensor\n",
        "casted_float_tensor = tf.cast(original_int_tensor, dtype=tf.float32)\n",
        "print(\"\\nCasted Float Tensor:\", casted_float_tensor)\n",
        "print(\"Casted Tensor Dtype:\", casted_float_tensor.dtype)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Integer Tensor: tf.Tensor([1 2 3 4 5], shape=(5,), dtype=int32)\n",
            "Original Tensor Dtype: <dtype: 'int32'>\n",
            "\n",
            "Casted Float Tensor: tf.Tensor([1. 2. 3. 4. 5.], shape=(5,), dtype=float32)\n",
            "Casted Tensor Dtype: <dtype: 'float32'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bbce41b"
      },
      "source": [
        "## Keras for Model Building Explained\n",
        "\n",
        "### Subtask:\n",
        "Provide a detailed explanation of Keras, focusing on how it provides a high-level API for building and training neural networks. Cover key components like Layers, Models (Sequential and Functional API), and the `compile()` and `fit()` methods.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d97be0c3"
      },
      "source": [
        "## 8️⃣ Keras API for Model Building\n",
        "\n",
        "Keras is a high-level, user-friendly API for building and training deep learning models. It runs on top of TensorFlow (and other backends like JAX or PyTorch, though TensorFlow is the primary one). Keras was designed for fast experimentation, making it easier and quicker to go from idea to result.\n",
        "\n",
        "Its key advantages include:\n",
        "*   **Simplicity and User-Friendliness**: Keras has a clear and concise API, making it easy to learn and use.\n",
        "*   **Modularity**: Models are built by combining configurable building blocks, making them highly flexible.\n",
        "*   **Easy Experimentation**: Its design allows for rapid prototyping and quick iteration on model architectures.\n",
        "\n",
        "Let's delve into its core components:\n",
        "\n",
        "### a. Layers: The Fundamental Building Blocks\n",
        "\n",
        "In Keras, **Layers** are the core building blocks of neural networks. Each layer performs a specific type of computation on the input data and passes its output to the next layer. Examples include `Dense` (fully connected), `Conv2D` (convolutional for images), `LSTM` (for recurrent networks), and `Flatten`.\n",
        "\n",
        "Layers handle much of the complexity of neural network design, such as weight initialization, activation functions, and bias regularization. You simply stack them together to create a model.\n",
        "\n",
        "### b. Models: Assembling Layers\n",
        "\n",
        "Keras provides two main ways to build models by assembling layers:\n",
        "\n",
        "1.  **Sequential API**: This is the simplest way to build models, used for stacking layers in a linear fashion. It's suitable for simple feed-forward networks (stacks of layers where each layer has exactly one input tensor and one output tensor). You create a `tf.keras.Sequential` object and then add layers to it sequentially.\n",
        "\n",
        "    ```python\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(64, activation='relu', input_shape=(784,)),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    ```\n",
        "\n",
        "2.  **Functional API**: This is a more flexible way to build models that can handle arbitrary model architectures, including multi-input models, multi-output models, and models with shared layers or non-linear topology (e.g., residual connections). You define the input layer first, then define how layers connect to each other by calling layers on tensors.\n",
        "\n",
        "    ```python\n",
        "    inputs = tf.keras.Input(shape=(784,))\n",
        "    x = tf.keras.layers.Dense(64, activation='relu')(inputs)\n",
        "    outputs = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    ```\n",
        "\n",
        "### c. `compile()` method: Configuring for Training\n",
        "\n",
        "After defining your model architecture, you need to configure its learning process using the `compile()` method. This step specifies:\n",
        "\n",
        "*   **Optimizer**: The algorithm used to update the model's weights during training (e.g., `'adam'`, `'sgd'`, `'rmsprop'`).\n",
        "*   **Loss Function**: The objective function that the model will try to minimize (e.g., `'categorical_crossentropy'` for multi-class classification, `'binary_crossentropy'` for binary classification, `'mse'` for regression).\n",
        "*   **Metrics**: A list of metrics to be evaluated by the model during training and testing (e.g., `'accuracy'`, `'precision'`, `'recall'`).\n",
        "\n",
        "    ```python\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    ```\n",
        "\n",
        "### d. `fit()` method: Training the Model\n",
        "\n",
        "Once compiled, the model can be trained using the `fit()` method. This method takes your training data and labels, and iteratively adjusts the model's weights to minimize the loss function.\n",
        "\n",
        "Key parameters for `fit()` include:\n",
        "\n",
        "*   **`x`**: Your input training data.\n",
        "*   **`y`**: Your target labels for the training data.\n",
        "*   **`epochs`**: The number of times the training algorithm will iterate over the entire training dataset. One epoch means that each sample in the training dataset has had an opportunity to update the internal model parameters.\n",
        "*   **`batch_size`**: The number of samples per gradient update. The training data is split into 'batches', and the model's weights are updated after processing each batch.\n",
        "*   **`validation_data`**: Data on which to evaluate the loss and any model metrics at the end of each epoch. This helps in monitoring for overfitting.\n",
        "\n",
        "    ```python\n",
        "    model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val))\n",
        "    ```\n",
        "\n",
        "By providing these high-level abstractions, Keras significantly streamlines the process of building, training, and evaluating deep learning models, allowing practitioners to focus more on model design and experimentation rather than low-level implementation details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f39a4949"
      },
      "source": [
        "## Keras Model Example (Sequential API)\n",
        "\n",
        "### Subtask:\n",
        "Add a code example demonstrating how to build, compile, and train a simple neural network using Keras's Sequential API for a basic task (e.g., a small regression or classification problem with dummy data).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c1f7b0e"
      },
      "source": [
        "### Keras Sequential API Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bf50410"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to demonstrate building, compiling, and training a simple neural network using Keras's Sequential API with dummy data, including imports, data generation, model definition, compilation, training, and prediction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "id": "d6cd4747",
        "outputId": "1c361829-1efa-4410-c71c-0da83a0ce8d6"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# 3. Create dummy input data X_train and target data y_train\n",
        "# For a simple regression problem: y = 2x + 1 + noise\n",
        "X_train = np.random.rand(100, 1).astype(np.float32) * 10 # 100 samples, 1 feature\n",
        "y_train = (2 * X_train + 1 + np.random.rand(100, 1) * 0.5).astype(np.float32)\n",
        "\n",
        "print(\"X_train sample:\\n\", X_train[:5])\n",
        "print(\"y_train sample:\\n\", y_train[:5])\n",
        "\n",
        "# 4. Define a simple Keras Sequential model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=10, activation='relu', input_shape=(1,)), # Input layer with 1 feature\n",
        "    tf.keras.layers.Dense(units=5, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1) # Output layer for regression (single output)\n",
        "])\n",
        "\n",
        "# 5. Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mean_squared_error', # MSE for regression\n",
        "    metrics=['mean_absolute_error'] # MAE as a metric\n",
        ")\n",
        "\n",
        "print(\"\\nModel summary:\")\n",
        "model.summary()\n",
        "\n",
        "# 6. Train the model using the fit() method\n",
        "print(\"\\nTraining the model...\")\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=100, # A reasonable number of epochs\n",
        "    verbose=0 # Suppress verbose output during training\n",
        ")\n",
        "\n",
        "print(\"Model training finished. Last epoch MAE: \", history.history['mean_absolute_error'][-1])\n",
        "\n",
        "# 7. Make a prediction on a new dummy input\n",
        "new_X = np.array([[5.0]])\n",
        "prediction = model.predict(new_X)\n",
        "print(f\"\\nPrediction for input {new_X[0][0]}: {prediction[0][0]:.2f}\")\n",
        "print(f\"Expected output (approx): {2 * new_X[0][0] + 1:.2f}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train sample:\n",
            " [[2.8546247]\n",
            " [8.797181 ]\n",
            " [5.6863647]\n",
            " [7.326491 ]\n",
            " [1.841246 ]]\n",
            "y_train sample:\n",
            " [[ 6.8696613]\n",
            " [18.728523 ]\n",
            " [12.702781 ]\n",
            " [16.040545 ]\n",
            " [ 5.062539 ]]\n",
            "\n",
            "Model summary:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │            \u001b[38;5;34m20\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m55\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m81\u001b[0m (324.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">81</span> (324.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m81\u001b[0m (324.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">81</span> (324.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training the model...\n",
            "Model training finished. Last epoch MAE:  2.1660900115966797\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "\n",
            "Prediction for input 5.0: 9.10\n",
            "Expected output (approx): 11.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a1fa0e9"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code generated a UserWarning regarding the `input_shape` argument in `tf.keras.layers.Dense` when used in a `Sequential` model. To adhere to best practices and eliminate the warning, I will modify the model definition to explicitly use `tf.keras.Input` as the first layer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "id": "2215179a",
        "outputId": "0f8caa00-ef22-4e62-8d83-71aae00d27d0"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# 3. Create dummy input data X_train and target data y_train\n",
        "# For a simple regression problem: y = 2x + 1 + noise\n",
        "X_train = np.random.rand(100, 1).astype(np.float32) * 10 # 100 samples, 1 feature\n",
        "y_train = (2 * X_train + 1 + np.random.rand(100, 1) * 0.5).astype(np.float32)\n",
        "\n",
        "print(\"X_train sample:\\n\", X_train[:5])\n",
        "print(\"y_train sample:\\n\", y_train[:5])\n",
        "\n",
        "# 4. Define a simple Keras Sequential model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.Input(shape=(1,)), # Explicitly define input layer\n",
        "    tf.keras.layers.Dense(units=10, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=5, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1) # Output layer for regression (single output)\n",
        "])\n",
        "\n",
        "# 5. Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mean_squared_error', # MSE for regression\n",
        "    metrics=['mean_absolute_error'] # MAE as a metric\n",
        ")\n",
        "\n",
        "print(\"\\nModel summary:\")\n",
        "model.summary()\n",
        "\n",
        "# 6. Train the model using the fit() method\n",
        "print(\"\\nTraining the model...\")\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=100, # A reasonable number of epochs\n",
        "    verbose=0 # Suppress verbose output during training\n",
        ")\n",
        "\n",
        "print(\"Model training finished. Last epoch MAE: \", history.history['mean_absolute_error'][-1])\n",
        "\n",
        "# 7. Make a prediction on a new dummy input\n",
        "new_X = np.array([[5.0]])\n",
        "prediction = model.predict(new_X)\n",
        "print(f\"\\nPrediction for input {new_X[0][0]}: {prediction[0][0]:.2f}\")\n",
        "print(f\"Expected output (approx): {2 * new_X[0][0] + 1:.2f}\")\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train sample:\n",
            " [[1.9543722]\n",
            " [3.1075013]\n",
            " [1.7027795]\n",
            " [1.2941501]\n",
            " [5.463421 ]]\n",
            "y_train sample:\n",
            " [[ 5.244688 ]\n",
            " [ 7.416757 ]\n",
            " [ 4.582172 ]\n",
            " [ 3.7732246]\n",
            " [11.997667 ]]\n",
            "\n",
            "Model summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │            \u001b[38;5;34m20\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m55\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m81\u001b[0m (324.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">81</span> (324.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m81\u001b[0m (324.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">81</span> (324.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training the model...\n",
            "Model training finished. Last epoch MAE:  0.17891563475131989\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "\n",
            "Prediction for input 5.0: 11.29\n",
            "Expected output (approx): 11.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a2a96dc"
      },
      "source": [
        "## Keras Model Example (Functional API)\n",
        "\n",
        "### Subtask:\n",
        "Add a code example demonstrating how to build, compile, and train a simple neural network using Keras's Functional API. This should highlight its flexibility compared to the Sequential API (e.g., a simple multi-input or non-linear model).\n",
        "\n",
        "#### Instructions\n",
        "1. Add a new markdown cell with the heading 'Keras Functional API Example'.\n",
        "2. In a new code cell, import `tensorflow` and `numpy`.\n",
        "3. Create dummy input data for a slightly more complex problem, suitable for demonstrating the Functional API's advantages. For example, two input features `X1_train`, `X2_train` and a target `y_train` where `y = X1 + 2*X2 + noise`.\n",
        "4. Define a simple Keras model using the **Functional API**. This should involve defining `tf.keras.Input` objects, connecting layers by calling layers on tensors, and finally creating a `tf.keras.Model` by specifying inputs and outputs.\n",
        "5. Compile the model, choosing an appropriate optimizer, loss function (e.g., 'mse' for regression), and metrics.\n",
        "6. Train the model using the `fit()` method with your dummy data. Specify `epochs` and `batch_size`.\n",
        "7. After training, optionally print a summary of the model and make a prediction on new dummy inputs, showcasing how predictions are made with multiple inputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac166be7"
      },
      "source": [
        "## Keras Model Example (Functional API)\n",
        "\n",
        "### Subtask:\n",
        "Add a code example demonstrating how to build, compile, and train a simple neural network using Keras's Functional API. This should highlight its flexibility compared to the Sequential API (e.g., a simple multi-input or non-linear model).\n",
        "\n",
        "#### Instructions\n",
        "1. Add a new markdown cell with the heading 'Keras Functional API Example'.\n",
        "2. In a new code cell, import `tensorflow` and `numpy`.\n",
        "3. Create dummy input data for a slightly more complex problem, suitable for demonstrating the Functional API's advantages. For example, two input features `X1_train`, `X2_train` and a target `y_train` where `y = X1 + 2*X2 + noise`.\n",
        "4. Define a simple Keras model using the **Functional API**. This should involve defining `tf.keras.Input` objects, connecting layers by calling layers on tensors, and finally creating a `tf.keras.Model` by specifying inputs and outputs.\n",
        "5. Compile the model, choosing an appropriate optimizer, loss function (e.g., 'mse' for regression), and metrics.\n",
        "6. Train the model using the `fit()` method with your dummy data. Specify `epochs` and `batch_size`.\n",
        "7. After training, optionally print a summary of the model and make a prediction on new dummy inputs, showcasing how predictions are made with multiple inputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9080557"
      },
      "source": [
        "### Keras Functional API Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4715a90f"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to create dummy data for a multi-input regression problem and then build, compile, train, and predict using Keras's Functional API, demonstrating its flexibility.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "id": "a766aa76",
        "outputId": "6f18594a-61c4-4a92-809d-8c8259e5f8d1"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# 3. Create dummy input data for a multi-input regression problem\n",
        "# For a simple regression problem with two inputs: y = 2*X1 + 3*X2 + 1 + noise\n",
        "np.random.seed(42) # for reproducibility\n",
        "X1_train = np.random.rand(100, 1).astype(np.float32) * 10\n",
        "X2_train = np.random.rand(100, 1).astype(np.float32) * 5\n",
        "y_train = (2 * X1_train + 3 * X2_train + 1 + np.random.rand(100, 1) * 0.5).astype(np.float32)\n",
        "\n",
        "print(\"X1_train sample:\\n\", X1_train[:5])\n",
        "print(\"X2_train sample:\\n\", X2_train[:5])\n",
        "print(\"y_train sample:\\n\", y_train[:5])\n",
        "\n",
        "# 4. Define a simple Keras model using the Functional API\n",
        "# Define input layers\n",
        "input1 = tf.keras.Input(shape=(1,), name='input_feature_1')\n",
        "input2 = tf.keras.Input(shape=(1,), name='input_feature_2')\n",
        "\n",
        "# Combine inputs\n",
        "concatenated_inputs = tf.keras.layers.concatenate([input1, input2])\n",
        "\n",
        "# Add hidden layers\n",
        "hidden1 = tf.keras.layers.Dense(units=10, activation='relu')(concatenated_inputs)\n",
        "hidden2 = tf.keras.layers.Dense(units=5, activation='relu')(hidden1)\n",
        "\n",
        "# Output layer for regression (single output)\n",
        "output = tf.keras.layers.Dense(units=1, name='output_layer')(hidden2)\n",
        "\n",
        "# Create the model by specifying inputs and outputs\n",
        "model_functional = tf.keras.Model(inputs=[input1, input2], outputs=output)\n",
        "\n",
        "# 5. Compile the model\n",
        "model_functional.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mean_squared_error', # MSE for regression\n",
        "    metrics=['mean_absolute_error'] # MAE as a metric\n",
        ")\n",
        "\n",
        "print(\"\\nModel Functional summary:\")\n",
        "model_functional.summary()\n",
        "\n",
        "# 6. Train the model using the fit() method\n",
        "print(\"\\nTraining the Functional model...\")\n",
        "history_functional = model_functional.fit(\n",
        "    {'input_feature_1': X1_train, 'input_feature_2': X2_train}, y_train,\n",
        "    epochs=100,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "print(\"Functional Model training finished. Last epoch MAE: \", history_functional.history['mean_absolute_error'][-1])\n",
        "\n",
        "# 7. Make a prediction on new dummy inputs\n",
        "new_X1 = np.array([[5.0]])\n",
        "new_X2 = np.array([[2.0]])\n",
        "prediction_functional = model_functional.predict({'input_feature_1': new_X1, 'input_feature_2': new_X2})\n",
        "\n",
        "print(f\"\\nPrediction for input X1={new_X1[0][0]}, X2={new_X2[0][0]}: {prediction_functional[0][0]:.2f}\")\n",
        "print(f\"Expected output (approx): {2 * new_X1[0][0] + 3 * new_X2[0][0] + 1:.2f}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X1_train sample:\n",
            " [[3.7454011]\n",
            " [9.507143 ]\n",
            " [7.319939 ]\n",
            " [5.986585 ]\n",
            " [1.5601864]]\n",
            "X2_train sample:\n",
            " [[0.15714593]\n",
            " [3.1820521 ]\n",
            " [1.5717798 ]\n",
            " [2.5428534 ]\n",
            " [4.5378323 ]]\n",
            "y_train sample:\n",
            " [[ 9.283256]\n",
            " [29.602512]\n",
            " [20.436031]\n",
            " [21.051008]\n",
            " [18.037085]]\n",
            "\n",
            "Model Functional summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_feature_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_feature_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ input_feature_1[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ input_feature_2[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │         \u001b[38;5;34m30\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │         \u001b[38;5;34m55\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ output_layer        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m6\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_feature_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_feature_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_feature_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ input_feature_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ output_layer        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m91\u001b[0m (364.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">91</span> (364.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m91\u001b[0m (364.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">91</span> (364.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training the Functional model...\n",
            "Functional Model training finished. Last epoch MAE:  1.4649841785430908\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
            "\n",
            "Prediction for input X1=5.0, X2=2.0: 17.25\n",
            "Expected output (approx): 17.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b426a114"
      },
      "source": [
        "## 9️⃣ `tf.GradientTape`: Advanced Automatic Differentiation\n",
        "\n",
        "### Subtask:\n",
        "Explain `tf.GradientTape` for advanced automatic differentiation, providing examples for both nested tapes (for higher-order derivatives) and persistent tapes (for computing gradients multiple times on the same set of operations).\n",
        "\n",
        "#### Instructions\n",
        "1. Add a new markdown cell with the heading 'tf.GradientTape: Advanced Automatic Differentiation'.\n",
        "2. Provide an explanation of `tf.GradientTape`, its purpose, and how it works by recording operations.\n",
        "3. Explain **Nested Tapes** and their use case (e.g., computing second-order derivatives).\n",
        "4. Explain **Persistent Tapes** and their use case (e.g., computing gradients for multiple optimizers or loss components).\n",
        "5. Add a code example demonstrating how to use a **Nested Tape** to calculate a second-order derivative.\n",
        "6. Add a code example demonstrating how to use a **Persistent Tape** to calculate gradients multiple times."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1accc26c"
      },
      "source": [
        "### What is `tf.GradientTape`?\n",
        "\n",
        "Automatic differentiation is crucial for training neural networks, as it allows for the efficient computation of gradients needed for optimization algorithms like gradient descent. TensorFlow provides the `tf.GradientTape` API for this purpose.\n",
        "\n",
        "`tf.GradientTape` is a powerful mechanism in TensorFlow that records operations performed during a forward pass. When you later call the `tape.gradient()` method, it uses these recorded operations to compute the gradients of a target (usually the loss) with respect to some source (usually the model's trainable variables).\n",
        "\n",
        "**How it works:**\n",
        "\n",
        "1.  **Recording:** You typically use `with tf.GradientTape() as tape:` to create a gradient tape context. All operations executed within this context that involve `tf.Variable`s (or `tf.Tensor`s explicitly watched by the tape) are recorded.\n",
        "2.  **Tracking Variables:** By default, `tf.GradientTape` automatically tracks any `tf.Variable`s that are accessed inside the `with` block. If you want to compute gradients with respect to a `tf.Tensor` (which is not a `tf.Variable`), you must explicitly watch it using `tape.watch(tensor)`.\n",
        "3.  **Computing Gradients:** After the operations are recorded, you call `tape.gradient(target, sources)`:\n",
        "    *   `target`: The tensor whose gradient you want to compute (e.g., the loss scalar).\n",
        "    *   `sources`: A list or tuple of tensors/variables with respect to which you want to compute the gradient (e.g., your model's weights and biases).\n",
        "4.  **Disposal:** By default, the resources held by a `GradientTape` are released as soon as the `gradient()` method is called. This means a single `GradientTape` can only compute one set of gradients.\n",
        "\n",
        "`tf.GradientTape` allows for flexible gradient computation, supporting arbitrary nested computations, control flow, and higher-order derivatives, which we will explore next."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c42deb3"
      },
      "source": [
        "### Nested Tapes: Computing Higher-Order Derivatives\n",
        "\n",
        "**Nested tapes** allow you to compute higher-order derivatives (e.g., second, third, or even higher derivatives). This is achieved by nesting one `tf.GradientTape` inside another. The outer tape records the operations of the inner tape's gradient computation.\n",
        "\n",
        "**Use Case:**\n",
        "\n",
        "*   **Second-order optimization methods:** Some advanced optimization algorithms, like Newton's method, require second-order derivatives (Hessians).\n",
        "*   **Meta-learning:** Training models that learn how to learn often involves optimizing an objective function with respect to hyperparameters, which can require gradients of gradients.\n",
        "*   **Adversarial examples and robustness research:** Computing sensitivities of models to input perturbations might involve higher-order derivatives.\n",
        "\n",
        "When you nest tapes:\n",
        "\n",
        "1.  The **inner tape** computes the first-order gradient of a target with respect to a source.\n",
        "2.  The **outer tape** then records the operations involved in *computing this first-order gradient*. When you call `gradient()` on the outer tape, it computes the gradient of the first-order gradient, effectively yielding the second-order derivative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d76a359"
      },
      "source": [
        "### Persistent Tapes: Computing Gradients Multiple Times\n",
        "\n",
        "By default, a `tf.GradientTape` is **non-persistent**, meaning the resources it holds are released as soon as the `tape.gradient()` method is called. This is efficient for typical training loops where gradients are computed once per iteration.\n",
        "\n",
        "However, there are scenarios where you might need to compute gradients multiple times over the same set of recorded operations. For these cases, TensorFlow provides **persistent tapes**.\n",
        "\n",
        "**Use Cases:**\n",
        "\n",
        "*   **Multiple Optimizers:** In models with multiple components that are updated by different optimizers (e.g., Generative Adversarial Networks (GANs) with a generator and a discriminator), you might need to compute gradients for different loss functions with respect to different sets of variables, all based on the same forward pass.\n",
        "*   **Regularization Techniques:** When applying complex regularization terms that require separate gradient computations (e.g., gradient penalties in GANs).\n",
        "*   **Debugging and Analysis:** When you need to inspect intermediate gradients or compute gradients with respect to different targets or sources for analysis purposes.\n",
        "\n",
        "To create a persistent tape, you simply pass `persistent=True` to the `tf.GradientTape` constructor:\n",
        "\n",
        "```python\n",
        "with tf.GradientTape(persistent=True) as tape:\n",
        "    # Record operations\n",
        "```\n",
        "\n",
        "**Important:** When using a persistent tape, you are responsible for explicitly releasing its resources using `del tape` after you are done with it to free up memory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9e34416"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction #5 of the subtask, I will now add a code example demonstrating how to use a nested `tf.GradientTape` to calculate a second-order derivative.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fca20da",
        "outputId": "c4c490ee-84f5-4ac9-abd0-2552f0c2f91d"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define a variable\n",
        "x = tf.Variable(3.0)\n",
        "\n",
        "print(f\"Original value of x: {x.numpy()}\")\n",
        "\n",
        "# Outer tape for second-order derivative\n",
        "with tf.GradientTape() as outer_tape:\n",
        "    outer_tape.watch(x) # Explicitly watch x for the outer tape\n",
        "\n",
        "    # Inner tape for first-order derivative\n",
        "    with tf.GradientTape() as inner_tape:\n",
        "        inner_tape.watch(x) # Explicitly watch x for the inner tape\n",
        "\n",
        "        # Define the function: y = x^3\n",
        "        y = x ** 3\n",
        "\n",
        "    # Compute the first-order derivative (dy_dx) within the outer tape's scope\n",
        "    # dy_dx = d(x^3)/dx = 3x^2\n",
        "    dy_dx = inner_tape.gradient(y, x)\n",
        "    print(f\"\\nFirst-order derivative (dy_dx) at x={x.numpy()}: {dy_dx.numpy()}\")\n",
        "\n",
        "# Compute the second-order derivative (d2y_dx2) from the outer tape\n",
        "# d2y_dx2 = d(3x^2)/dx = 6x\n",
        "d2y_dx2 = outer_tape.gradient(dy_dx, x)\n",
        "print(f\"Second-order derivative (d2y_dx2) at x={x.numpy()}: {d2y_dx2.numpy()}\")\n",
        "\n",
        "# Expected values:\n",
        "# dy_dx = 3 * (3^2) = 27\n",
        "# d2y_dx2 = 6 * 3 = 18"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original value of x: 3.0\n",
            "\n",
            "First-order derivative (dy_dx) at x=3.0: 27.0\n",
            "Second-order derivative (d2y_dx2) at x=3.0: 18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1d54f99"
      },
      "source": [
        "**Reasoning**:\n",
        "As per instruction #6 of the subtask, I will now add a code example demonstrating how to use a persistent `tf.GradientTape` to calculate gradients multiple times. I will compute gradients of two different functions with respect to the same variable using a single persistent tape.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e7efc72",
        "outputId": "864813c8-5f56-470c-93ed-6d6e6cdadf3f"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define a variable\n",
        "x_persistent = tf.Variable(5.0)\n",
        "\n",
        "print(f\"Original value of x_persistent: {x_persistent.numpy()}\")\n",
        "\n",
        "# Create a persistent GradientTape\n",
        "# Remember to explicitly delete the tape after use to free resources\n",
        "with tf.GradientTape(persistent=True) as tape:\n",
        "    tape.watch(x_persistent) # Explicitly watch the variable if not a tf.Variable\n",
        "\n",
        "    # Define two different functions using x_persistent\n",
        "    y1 = x_persistent ** 2 # f(x) = x^2\n",
        "    y2 = tf.math.sin(x_persistent) # g(x) = sin(x)\n",
        "    y3 = x_persistent * 4 # h(x) = 4x\n",
        "\n",
        "# Compute gradients of y1 with respect to x_persistent\n",
        "# dy1_dx = d(x^2)/dx = 2x\n",
        "dy1_dx = tape.gradient(y1, x_persistent)\n",
        "print(f\"\\nGradient of y1=x^2 with respect to x_persistent at x={x_persistent.numpy()}: {dy1_dx.numpy()}\")\n",
        "\n",
        "# Compute gradients of y2 with respect to x_persistent (using the same tape)\n",
        "# dy2_dx = d(sin(x))/dx = cos(x)\n",
        "dy2_dx = tape.gradient(y2, x_persistent)\n",
        "print(f\"Gradient of y2=sin(x) with respect to x_persistent at x={x_persistent.numpy()}: {dy2_dx.numpy()}\")\n",
        "\n",
        "# Compute gradients of y3 with respect to x_persistent (using the same tape)\n",
        "# dy3_dx = d(4x)/dx = 4\n",
        "dy3_dx = tape.gradient(y3, x_persistent)\n",
        "print(f\"Gradient of y3=4x with respect to x_persistent at x={x_persistent.numpy()}: {dy3_dx.numpy()}\")\n",
        "\n",
        "# It's important to delete the persistent tape when you are done with it\n",
        "del tape\n",
        "\n",
        "# Expected values at x=5.0:\n",
        "# dy1_dx = 2 * 5 = 10\n",
        "# dy2_dx = cos(5.0) ≈ 0.28366\n",
        "# dy3_dx = 4"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original value of x_persistent: 5.0\n",
            "\n",
            "Gradient of y1=x^2 with respect to x_persistent at x=5.0: 10.0\n",
            "Gradient of y2=sin(x) with respect to x_persistent at x=5.0: 0.28366219997406006\n",
            "Gradient of y3=4x with respect to x_persistent at x=5.0: 4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8da78b12"
      },
      "source": [
        "## TensorFlow and Keras Summary\n",
        "\n",
        "### Subtask:\n",
        "Conclude with a summary of the key takeaways, highlighting the strengths of TensorFlow and Keras together for deep learning development.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5648ff25"
      },
      "source": [
        "### Key Takeaways: TensorFlow and Keras\n",
        "\n",
        "TensorFlow and Keras together form a robust and versatile ecosystem for deep learning, catering to both rapid prototyping and advanced research needs. Here's a summary of their combined strengths:\n",
        "\n",
        "*   **TensorFlow's Core Strengths**: At its heart, TensorFlow provides the foundational components for numerical computation, particularly with its `tf.Tensor` objects—multi-dimensional arrays optimized for performance on various hardware, including GPUs and TPUs. Its powerful automatic differentiation system, exposed through `tf.GradientTape`, is crucial for efficiently computing gradients required for training neural networks.\n",
        "\n",
        "*   **Keras's Role**: Keras acts as a high-level, user-friendly API that significantly simplifies the process of building, configuring, and training deep learning models. It abstracts away much of the complexity, offering intuitive ways to define model architectures (via Sequential and Functional APIs), compile models with optimizers and loss functions, and train them with the `fit()` method. Keras prioritizes ease of use and fast experimentation, making deep learning more accessible.\n",
        "\n",
        "*   **Synergy**: The true power lies in their synergy. Keras, running as a high-level API on top of TensorFlow, allows developers to leverage TensorFlow's robust and scalable backend while enjoying Keras's elegant and intuitive interface. This means you get the best of both worlds: Keras's simplicity for quick model development and TensorFlow's underlying power for complex computations, distributed training, and production deployment.\n",
        "\n",
        "*   **Practical Implications**: This combination empowers users to:\n",
        "    *   **Rapidly prototype** and experiment with different model architectures and hyperparameters using Keras.\n",
        "    *   **Dive into low-level details** and custom operations when needed, utilizing TensorFlow's flexible API for advanced research or specific optimizations.\n",
        "    *   **Benefit from performance** optimizations and deployment capabilities offered by TensorFlow, even when developing with Keras.\n",
        "\n",
        "In essence, TensorFlow provides the muscle and intelligence for deep learning computations, while Keras offers the streamlined interface to effectively command that power, making the journey from idea to deployed model smoother and more efficient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "515b856c"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Review the generated explanations and code examples, ensuring they comprehensively cover TensorFlow and Keras concepts as requested by the user.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2de1f6d1"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **TensorFlow Type Casting**: The `tf.cast` function successfully converted a `tf.int32` tensor `[1, 2, 3, 4, 5]` into a `tf.float32` tensor `[1.0, 2.0, 3.0, 4.0, 5.0]`, demonstrating data type conversion.\n",
        "*   **Keras API Explanation**: A comprehensive explanation of Keras was provided, covering Layers, Sequential and Functional APIs, and the usage of `compile()` and `fit()` methods, supported by illustrative code snippets.\n",
        "*   **Keras Sequential API**: A simple regression model, trained on dummy data (`y = 2x + 1 + noise`), demonstrated the Sequential API. The model's prediction for an input of `5.0` was approximately `11.29`, closely matching the expected value of `11.00`, indicating successful learning.\n",
        "*   **Keras Functional API**: A multi-input regression model, trained on dummy data (`y = 2*X1 + 3*X2 + 1 + noise`), showcased the Functional API's flexibility. For inputs `X1=5.0` and `X2=2.0`, the model predicted approximately `17.25`, aligning well with the expected value of `17.00`.\n",
        "*   **`tf.GradientTape` for Higher-Order Derivatives**:\n",
        "    *   **Nested Tapes** were successfully used to compute a second-order derivative for the function \\(y = x^3\\) at \\(x = 3.0\\). The first-order derivative was \\(27.0\\) (expected \\(3x^2 = 27\\)), and the second-order derivative was \\(18.0\\) (expected \\(6x = 18\\)).\n",
        "    *   **Persistent Tapes** were demonstrated by computing gradients for multiple functions (\\(y_1 = x^2\\), \\(y_2 = \\sin(x)\\), \\(y_3 = 4x\\)) at \\(x = 5.0\\) from a single tape instance. The gradients computed were \\(10.0\\) (expected \\(2x\\)), approximately \\(0.28366\\) (expected \\(\\cos(x)\\)), and \\(4.0\\) (expected \\(4\\)), respectively.\n",
        "*   **TensorFlow and Keras Synergy**: The summary highlighted TensorFlow's foundational role in numerical computation and automatic differentiation (via `tf.GradientTape`), Keras's high-level API for simplifying model building and training, and their combined strength for both rapid prototyping and advanced deep learning research.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The comprehensive examples and explanations provided offer a strong foundation for understanding key TensorFlow and Keras concepts, from basic data type manipulation to advanced automatic differentiation and neural network construction.\n",
        "*   Future explorations could involve applying these concepts to real-world datasets and more complex model architectures to further solidify understanding and demonstrate practical applications.\n"
      ]
    }
  ]
}